{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparing randomized search and grid search for hyperparameter estimation\n",
    "\n",
    "\n",
    "Compare randomized search and grid search for optimizing hyperparameters of a\n",
    "random forest.\n",
    "All parameters that influence the learning are searched simultaneously\n",
    "(except for the number of estimators, which poses a time / quality tradeoff).\n",
    "\n",
    "The randomized search and the grid search explore exactly the same space of\n",
    "parameters. The result in parameter settings is quite similar, while the run\n",
    "time for randomized search is drastically lower.\n",
    "\n",
    "The performance is slightly worse for the randomized search, though this\n",
    "is most likely a noise effect and would not carry over to a held-out test set.\n",
    "\n",
    "Note that in practice, one would not search over this many different parameters\n",
    "simultaneously using grid search, but pick only the ones deemed most important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561 15\n",
      "16281 15\n",
      "(32561, 105)\n",
      "(32561, 14) (32561, 14)\n",
      "[[  3.90000000e+01   7.75160000e+04   1.30000000e+01   2.17400000e+03\n",
      "    0.00000000e+00   4.00000000e+01]\n",
      " [  5.00000000e+01   8.33110000e+04   1.30000000e+01   0.00000000e+00\n",
      "    0.00000000e+00   1.30000000e+01]\n",
      " [  3.80000000e+01   2.15646000e+05   9.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   4.00000000e+01]]\n",
      "[[ 0.03067056 -1.06361075  1.13473876  0.1484529  -0.21665953 -0.03542945]\n",
      " [ 0.83710898 -1.008707    1.13473876 -0.14592048 -0.21665953 -2.22215312]\n",
      " [-0.04264203  0.2450785  -0.42005962 -0.14592048 -0.21665953 -0.03542945]]\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import loadData,getScaledAndOneHotEncoderedX,getLineFromFile,simpleScale,testModelOnData,scaleWithFeaturesAndKeepLocation\n",
    "from data_preprocessing import checkNegative\n",
    "from data_preprocessing import decisionTreeDemo\n",
    "\n",
    "\n",
    "X, y, TX, Ty = loadData()\n",
    "\n",
    "scaledAndOneHotX = getScaledAndOneHotEncoderedX(X) \n",
    "scaledAndOneHotTX = getScaledAndOneHotEncoderedX(TX) \n",
    "print(scaledAndOneHotX.shape)\n",
    "\n",
    "continuous_features = list(map(lambda x: x - 1, [1, 3, 5, 11, 12, 13]))\n",
    "scaledX = scaleWithFeaturesAndKeepLocation(X, continuous_features)\n",
    "scaledTX = scaleWithFeaturesAndKeepLocation(TX, continuous_features)\n",
    "print(X.shape, scaledX.shape)\n",
    "\n",
    "X12 = X[:3]\n",
    "scaledX12 = scaledX[:3]\n",
    "print(X12[:,continuous_features])\n",
    "print(scaledX12[:,continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "RandomizedSearchCV took 1345.55 seconds for 1000 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.913 (std: 0.002)\n",
      "Parameters: {'max_depth': 11, 'min_samples_split': 6, 'n_estimators': 53, 'criterion': 'gini', 'min_samples_leaf': 4, 'bootstrap': True, 'max_features': 'sqrt', 'oob_score': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.913 (std: 0.003)\n",
      "Parameters: {'criterion': 'gini', 'min_samples_split': 7, 'max_depth': 11, 'n_estimators': 77, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'log2', 'oob_score': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.912 (std: 0.003)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 11, 'n_estimators': 74, 'min_samples_split': 6, 'bootstrap': True, 'max_features': 'log2', 'min_samples_leaf': 3, 'oob_score': True}\n",
      "\n",
      "GridSearchCV took 899.73 seconds for 576 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.914 (std: 0.003)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 110, 'criterion': 'gini', 'bootstrap': True, 'max_features': 'log2', 'min_samples_leaf': 3, 'oob_score': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.914 (std: 0.003)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 110, 'min_samples_split': 10, 'bootstrap': True, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'oob_score': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.914 (std: 0.003)\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 110, 'criterion': 'gini', 'bootstrap': True, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'oob_score': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "# digits = load_digits()\n",
    "# X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_grid = {\n",
    "                'n_estimators':sp_randint(50,110),\n",
    "                \"max_depth\": sp_randint(5,12),\n",
    "                \"max_features\": ['sqrt','log2'],\n",
    "                \"min_samples_split\": sp_randint(2, 10),\n",
    "                \"min_samples_leaf\": sp_randint(2, 10),\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                'oob_score':[True],\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 1000\n",
    "# random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "#                                    n_iter=n_iter_search)\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, cv=5,\n",
    "                    scoring='f1', #see above\n",
    "                    error_score=0, # to avoid crash\n",
    "                    n_iter=n_iter_search,\n",
    "                   n_jobs=5)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "                'n_estimators':[50,110],\n",
    "                \"max_depth\": [5,9,11,None],\n",
    "                \"max_features\": ['sqrt','log2'],\n",
    "                \"min_samples_split\": [2, 3, 10],\n",
    "                \"min_samples_leaf\": [2, 3, 10],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                'oob_score':[True],\n",
    "             }\n",
    "\n",
    "\n",
    "# run grid search\n",
    "# grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5,\n",
    "                    scoring='f1', #see above\n",
    "                    error_score=0, # to avoid crash\n",
    "                   n_jobs=5)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "            min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=73, n_jobs=1, oob_score=True, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.56      0.67      7841\n",
      "        1.0       0.87      0.96      0.92     24720\n",
      "\n",
      "avg / total       0.86      0.87      0.86     32561\n",
      "\n",
      "[[ 4418  3423]\n",
      " [  953 23767]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.54      0.65      3846\n",
      "        1.0       0.87      0.96      0.91     12435\n",
      "\n",
      "avg / total       0.85      0.86      0.85     16281\n",
      "\n",
      "[[ 2087  1759]\n",
      " [  533 11902]]\n",
      "\n",
      "\n",
      "[ 0.85424728  0.86032799  0.86114438]\n",
      "[ 0.85337018  0.85657248  0.85964373  0.86179361  0.86056511]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(oob_score=True, criterion= 'gini', n_estimators= 73, bootstrap= True, min_samples_split= 6, min_samples_leaf= 4, max_depth=10, max_features='sqrt')\n",
    "testModelOnData(clf, X, y, TX, Ty)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=11, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=75, n_jobs=1, oob_score=True, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.58      0.68      7841\n",
      "        1.0       0.88      0.96      0.92     24720\n",
      "\n",
      "avg / total       0.87      0.87      0.86     32561\n",
      "\n",
      "[[ 4528  3313]\n",
      " [  889 23831]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.55      0.65      3846\n",
      "        1.0       0.87      0.96      0.91     12435\n",
      "\n",
      "avg / total       0.86      0.86      0.85     16281\n",
      "\n",
      "[[ 2110  1736]\n",
      " [  528 11907]]\n",
      "\n",
      "\n",
      "[ 0.85590566  0.8615257   0.86317147]\n",
      "[ 0.85413788  0.8585688   0.86210074  0.86486486  0.86210074]\n"
     ]
    }
   ],
   "source": [
    "# 'oob_score': True, 'criterion': 'gini', 'n_estimators': 75, 'bootstrap': True, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 11, 'max_features': 'log2'\n",
    "from sklearn.ensemble import RandomForestClassifier                              \n",
    "clf = RandomForestClassifier(oob_score=True, criterion= 'gini', n_estimators= 75, bootstrap= True, min_samples_split= 9, min_samples_leaf= 2, max_depth=11, max_features='log2')\n",
    "testModelOnData(clf, X, y, TX, Ty)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country']\n",
    "class_names = [\"gt 50K\",\"le 50K\"]\n",
    "print(len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Usage:\n",
    "    saveTree2DotAndPdf(clf, feature_names=feature_names, class_names=class_names)\n",
    "'''\n",
    "def saveTree2DotAndPdf(clf, feature_names, class_names, file_name='tmp', showImage=False):\n",
    "    from sklearn import tree\n",
    "    dotFile = file_name+\".dot\"\n",
    "    pdfFile = file_name+\".pdf\"\n",
    "    with open(dotFile, 'w') as f:\n",
    "        f = tree.export_graphviz(clf, out_file=f,\n",
    "                            feature_names=feature_names,\n",
    "                            class_names=class_names,\n",
    "                            filled=True, \n",
    "                            rounded=True,  \n",
    "                            special_characters=True\n",
    "                            )\n",
    "    print('save to dot file done\\n')\n",
    "    import pydotplus \n",
    "    # dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "    # graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "    graph = pydotplus.graph_from_dot_file(dotFile)\n",
    "    graph.write_pdf(pdfFile)\n",
    "    print('save to pdf file done\\n')\n",
    "\n",
    "    \n",
    "    if showImage:\n",
    "        print('prepring to show the image, may take a long time...\\n')\n",
    "        from IPython.display import Image\n",
    "        Image(graph.create_png())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.63      0.69      7841\n",
      "        1.0       0.89      0.93      0.91     24720\n",
      "\n",
      "avg / total       0.86      0.86      0.86     32561\n",
      "\n",
      "[[ 4955  2886]\n",
      " [ 1636 23084]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.61      0.66      3846\n",
      "        1.0       0.88      0.93      0.91     12435\n",
      "\n",
      "avg / total       0.85      0.85      0.85     16281\n",
      "\n",
      "[[ 2337  1509]\n",
      " [  891 11544]]\n",
      "\n",
      "\n",
      "[ 0.84512622  0.84236226  0.84999539]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ATTENTION: IT IS TOTALLY WRONG\n",
    "please research the decisiontree for results.\n",
    "'''\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion= 'gini', min_samples_split= 9, min_samples_leaf= 2, max_depth=11, max_features='log2')\n",
    "testModelOnData(model, X, y, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to dot file done\n",
      "\n",
      "save to pdf file done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "saveTree2DotAndPdf(model, feature_names=feature_names, class_names=class_names, file_name='final_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
