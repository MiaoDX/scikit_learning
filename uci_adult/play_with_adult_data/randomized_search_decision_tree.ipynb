{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak decision tree with GridSearchCV and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561 15\n",
      "16281 15\n",
      "(32561, 105)\n",
      "(32561, 14) (32561, 14)\n",
      "[[  3.90000000e+01   7.75160000e+04   1.30000000e+01   2.17400000e+03\n",
      "    0.00000000e+00   4.00000000e+01]\n",
      " [  5.00000000e+01   8.33110000e+04   1.30000000e+01   0.00000000e+00\n",
      "    0.00000000e+00   1.30000000e+01]\n",
      " [  3.80000000e+01   2.15646000e+05   9.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   4.00000000e+01]]\n",
      "[[ 0.03067056 -1.06361075  1.13473876  0.1484529  -0.21665953 -0.03542945]\n",
      " [ 0.83710898 -1.008707    1.13473876 -0.14592048 -0.21665953 -2.22215312]\n",
      " [-0.04264203  0.2450785  -0.42005962 -0.14592048 -0.21665953 -0.03542945]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hand writen way to preprocess data\n",
    "\"\"\"\n",
    "\n",
    "from data_preprocessing import loadData,getScaledAndOneHotEncoderedX,getLineFromFile,simpleScale,testModelOnData,scaleWithFeaturesAndKeepLocation\n",
    "from data_preprocessing import checkNegative\n",
    "from data_preprocessing import decisionTreeDemo\n",
    "\n",
    "\n",
    "X, y, TX, Ty = loadData()\n",
    "\n",
    "scaledAndOneHotX = getScaledAndOneHotEncoderedX(X) \n",
    "scaledAndOneHotTX = getScaledAndOneHotEncoderedX(TX) \n",
    "print(scaledAndOneHotX.shape)\n",
    "\n",
    "continuous_features = list(map(lambda x: x - 1, [1, 3, 5, 11, 12, 13]))\n",
    "scaledX = scaleWithFeaturesAndKeepLocation(X, continuous_features)\n",
    "scaledTX = scaleWithFeaturesAndKeepLocation(TX, continuous_features)\n",
    "print(X.shape, scaledX.shape)\n",
    "\n",
    "X12 = X[:3]\n",
    "scaledX12 = scaledX[:3]\n",
    "print(X12[:,continuous_features])\n",
    "print(scaledX12[:,continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36631, 14) (36631,) (12211, 14) (12211,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pandas' way to preprocess data with train_test_split\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_preprocess_with_pandas import loadDataFromFileWithPandas\n",
    "\n",
    "base_dir = '../adult_data/'\n",
    "data_file = base_dir + 'adult.all.scale'\n",
    "X_train, X_test, y_train, y_test = loadDataFromFileWithPandas(data_file)\n",
    "X = X_train\n",
    "y = y_train\n",
    "TX = X_test\n",
    "Ty = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14) (32561,) (16281, 14) (16281,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pandas' way to preprocess data almost the same of orginal.\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_preprocess_with_pandas import loadDataFromFileWithPandas2\n",
    "\n",
    "base_dir = '../adult_data/'\n",
    "data_file = base_dir + 'adult.all.scale'\n",
    "X_train, X_test, y_train, y_test = loadDataFromFileWithPandas2(data_file)\n",
    "X = X_train\n",
    "y = y_train\n",
    "TX = X_test\n",
    "Ty = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 69.19 seconds for 500 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.675 (std: 0.014)\n",
      "Parameters: {'presort': False, 'min_samples_leaf': 4, 'splitter': 'best', 'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 13, 'max_features': None, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.674 (std: 0.015)\n",
      "Parameters: {'presort': False, 'min_samples_leaf': 3, 'max_features': None, 'min_samples_split': 6, 'max_depth': 13, 'criterion': 'entropy', 'splitter': 'best', 'class_weight': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.674 (std: 0.007)\n",
      "Parameters: {'presort': True, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 3, 'class_weight': 'balanced'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# build a classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_grid = {\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"splitter\": [\"best\",\"random\"],\n",
    "                \"max_features\": [\"sqrt\",\"log2\",None],\n",
    "                \"max_depth\": sp_randint(5,15),\n",
    "                \"min_samples_split\": sp_randint(2, 10),\n",
    "                \"min_samples_leaf\": sp_randint(1, 10),\n",
    "                \"class_weight\": [None, \"balanced\"],\n",
    "                \"presort\": [True, False],\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 500\n",
    "# random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "#                                    n_iter=n_iter_search)\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, cv=5,\n",
    "                    scoring='f1', #see above\n",
    "                    error_score=0, # to avoid crash\n",
    "                    n_iter=n_iter_search,\n",
    "                   n_jobs=6)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"splitter\": [\"best\",\"random\"],\n",
    "#                 \"max_features\": \n",
    "                \"max_depth\": list(range(5,13))[::2],\n",
    "                \"min_samples_split\": list(range(2,13))[::2],\n",
    "                \"min_samples_leaf\": list(range(1,11))[::2],\n",
    "                \"class_weight\": [None, \"balanced\"],\n",
    "                \"presort\": [True, False],\n",
    "             }\n",
    "\n",
    "\n",
    "# run grid search\n",
    "# grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5,\n",
    "                    scoring='f1', #see above\n",
    "                    error_score=0, # to avoid crash\n",
    "                   n_jobs=1)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country']\n",
    "class_names = [\"gt 50K\",\"le 50K\"]\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Usage:\n",
    "    saveTree2DotAndPdf(clf, feature_names=feature_names, class_names=class_names)\n",
    "'''\n",
    "def saveTree2DotAndPdf(clf, feature_names, class_names, file_name='tmp', showImage=False):\n",
    "    from sklearn import tree\n",
    "    dotFile = file_name+\".dot\"\n",
    "    pdfFile = file_name+\".pdf\"\n",
    "    with open(dotFile, 'w') as f:\n",
    "        f = tree.export_graphviz(clf, out_file=f,\n",
    "                            feature_names=feature_names,\n",
    "                            class_names=class_names,\n",
    "                            filled=True, \n",
    "                            rounded=True,  \n",
    "                            special_characters=True\n",
    "                            )\n",
    "    print('save to dot file done\\n')\n",
    "    import pydotplus \n",
    "    # dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "    # graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "    graph = pydotplus.graph_from_dot_file(dotFile)\n",
    "    graph.write_pdf(pdfFile)\n",
    "    print('save to pdf file done\\n')\n",
    "\n",
    "    \n",
    "    if showImage:\n",
    "        print('prepring to show the image, may take a long time...\\n')\n",
    "        from IPython.display import Image\n",
    "        Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=5,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=True, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91     24720\n",
      "        1.0       0.81      0.54      0.65      7841\n",
      "\n",
      "avg / total       0.85      0.86      0.85     32561\n",
      "\n",
      "[[23711  1009]\n",
      " [ 3621  4220]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.91     12435\n",
      "        1.0       0.79      0.53      0.63      3846\n",
      "\n",
      "avg / total       0.85      0.86      0.84     16281\n",
      "\n",
      "[[11892   543]\n",
      " [ 1816  2030]]\n",
      "\n",
      "\n",
      "[ 0.84918003  0.85655058  0.85248318]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Plot the answers.\n",
    "'''\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# 'splitter': 'best', 'max_depth': 8, 'max_features': None, 'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'presort': True, 'class_weight': None\n",
    "model = tree.DecisionTreeClassifier(criterion= 'entropy', min_samples_split=4, min_samples_leaf=5, max_depth=8,presort=True,max_features=None)\n",
    "\n",
    "testModelOnData(model, X, y, TX, Ty)\n",
    "# saveTree2DotAndPdf(model, feature_names=feature_names, class_names=class_names, file_name='final_results_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.54      0.65      7841\n",
      "        1.0       0.87      0.96      0.91     24720\n",
      "\n",
      "avg / total       0.86      0.86      0.85     32561\n",
      "\n",
      "[[ 4216  3625]\n",
      " [  916 23804]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.52      0.63      3846\n",
      "        1.0       0.87      0.96      0.91     12435\n",
      "\n",
      "avg / total       0.85      0.86      0.85     16281\n",
      "\n",
      "[[ 2011  1835]\n",
      " [  484 11951]]\n",
      "\n",
      "\n",
      "[ 0.85295744  0.85360236  0.85755091]\n"
     ]
    }
   ],
   "source": [
    "#{{'splitter': 'best', 'max_depth': 8, 'max_features': None, 'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'presort': False, 'class_weight': None}\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion= 'entropy', min_samples_split=3, min_samples_leaf=4, max_depth=8,presort=False)\n",
    "testModelOnData(model, X, y, TX, Ty)\n",
    "# saveTree2DotAndPdf(model, feature_names=feature_names, class_names=class_names, file_name='final_results_tree2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=5,\n",
      "            min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.64      0.69      7841\n",
      "        1.0       0.89      0.94      0.91     24720\n",
      "\n",
      "avg / total       0.86      0.86      0.86     32561\n",
      "\n",
      "[[ 4996  2845]\n",
      " [ 1598 23122]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.62      0.67      3846\n",
      "        1.0       0.89      0.93      0.91     12435\n",
      "\n",
      "avg / total       0.85      0.86      0.85     16281\n",
      "\n",
      "[[ 2371  1475]\n",
      " [  850 11585]]\n",
      "\n",
      "\n",
      "[ 0.85000921  0.85249678  0.85911729]\n"
     ]
    }
   ],
   "source": [
    "#{'splitter': 'best', 'criterion': 'entropy', 'min_samples_split': 9, 'class_weight': None, 'max_depth': 13, 'max_features': None, 'min_samples_leaf': 4, 'presort': False}\n",
    "#'max_depth': 9, 'splitter': 'best', 'criterion': 'gini', 'min_samples_split': 6, 'max_features': None, 'class_weight': None, 'min_samples_leaf': 5, 'presort': False\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion= 'gini', min_samples_split=6, min_samples_leaf=5, max_depth=9,presort=False)\n",
    "testModelOnData(model, X, y, TX, Ty)\n",
    "# saveTree2DotAndPdf(model, feature_names=feature_names, class_names=class_names, file_name='final_results_tree2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
