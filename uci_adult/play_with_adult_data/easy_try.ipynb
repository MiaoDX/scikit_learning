{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the preprocessing: transform description to number([male,female]->[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[【机器学习实验】scikit-learn的主要模块和基本使用](http://www.jianshu.com/p/1c6efdbce226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadXandY(fileName):\n",
    "    import numpy as np\n",
    "    \n",
    "    # load the CSV file as a numpy matrix\n",
    "    with open(fileName, 'r') as f:\n",
    "        dataset = np.loadtxt(f, delimiter=\",\")\n",
    "    \n",
    "    # separate the data from the target attributes\n",
    "    attrsize = len(dataset[0])\n",
    "    \n",
    "    print(len(dataset), attrsize)\n",
    "    \n",
    "    X = dataset[:,0:-1]\n",
    "    y = dataset[:,-1]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561 15\n",
      "16281 15\n"
     ]
    }
   ],
   "source": [
    "baseDir = 'H:/practice/scikit_class/scikit_learning/uci_adult/adult_data/'\n",
    "# baseDir = 'adult_data/'\n",
    "\n",
    "fileName = baseDir+'adult.data.num'\n",
    "\n",
    "testFileName = baseDir+'adult.test.num'\n",
    "\n",
    "X,y = loadXandY(fileName)\n",
    "TX,Ty = loadXandY(testFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with the missing value\n",
    "[reference](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simpleImputer(X):\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp.fit(X)\n",
    "    return imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = simpleImputer(X)\n",
    "TX = simpleImputer(TX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据归一化(Data Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simpleProcessing(X):\n",
    "    from sklearn import preprocessing\n",
    "    # normalize the data attributes\n",
    "    normalized_X = preprocessing.normalize(X)\n",
    "    # standardize the data attributes\n",
    "    standardized_X = preprocessing.scale(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = simpleProcessing(X)\n",
    "TX = simpleImputer(TX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征选择(Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15935025  0.04029886  0.16221789  0.03665789  0.08092646  0.06885382\n",
      "  0.08127987  0.09690376  0.01489237  0.02173822  0.09114213  0.03247581\n",
      "  0.09440882  0.01885385]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, X, y):\n",
    "    from sklearn import metrics\n",
    "    # make predictions\n",
    "    expected = y\n",
    "    predicted = model.predict(X)\n",
    "    # summarize the fit of the model\n",
    "    print(metrics.classification_report(expected, predicted))\n",
    "    print(metrics.confusion_matrix(expected, predicted))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.27      0.39      7841\n",
      "        1.0       0.81      0.97      0.88     24720\n",
      "\n",
      "avg / total       0.78      0.80      0.76     32561\n",
      "\n",
      "[[ 2087  5754]\n",
      " [  840 23880]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.26      0.39      3846\n",
      "        1.0       0.81      0.97      0.88     12435\n",
      "\n",
      "avg / total       0.79      0.80      0.76     16281\n",
      "\n",
      "[[ 1018  2828]\n",
      " [  414 12021]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "make_predictions(model, X, y)\n",
    "\n",
    "make_predictions(model, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      0.31      0.42      7841\n",
      "        1.0       0.81      0.95      0.88     24720\n",
      "\n",
      "avg / total       0.78      0.80      0.77     32561\n",
      "\n",
      "[[ 2441  5400]\n",
      " [ 1255 23465]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.31      0.41      3846\n",
      "        1.0       0.82      0.95      0.88     12435\n",
      "\n",
      "avg / total       0.77      0.80      0.77     16281\n",
      "\n",
      "[[ 1176  2670]\n",
      " [  663 11772]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 朴素贝叶斯\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "make_predictions(model, X, y)\n",
    "\n",
    "make_predictions(model, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.47      0.58      7841\n",
      "        1.0       0.85      0.95      0.90     24720\n",
      "\n",
      "avg / total       0.83      0.84      0.82     32561\n",
      "\n",
      "[[ 3650  4191]\n",
      " [ 1130 23590]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.32      0.41      3846\n",
      "        1.0       0.81      0.92      0.86     12435\n",
      "\n",
      "avg / total       0.75      0.78      0.75     16281\n",
      "\n",
      "[[ 1239  2607]\n",
      " [ 1028 11407]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K近邻\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "make_predictions(model, X, y)\n",
    "\n",
    "make_predictions(model, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      7841\n",
      "        1.0       1.00      1.00      1.00     24720\n",
      "\n",
      "avg / total       1.00      1.00      1.00     32561\n",
      "\n",
      "[[ 7841     0]\n",
      " [    1 24719]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.62      0.61      3846\n",
      "        1.0       0.88      0.87      0.88     12435\n",
      "\n",
      "avg / total       0.82      0.81      0.81     16281\n",
      "\n",
      "[[ 2378  1468]\n",
      " [ 1557 10878]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "make_predictions(model, X, y)\n",
    "\n",
    "make_predictions(model, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00      7841\n",
      "        1.0       1.00      1.00      1.00     24720\n",
      "\n",
      "avg / total       1.00      1.00      1.00     32561\n",
      "\n",
      "[[ 7766    75]\n",
      " [    0 24720]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      0.00      0.01      3846\n",
      "        1.0       0.76      1.00      0.87     12435\n",
      "\n",
      "avg / total       0.71      0.76      0.66     16281\n",
      "\n",
      "[[   15  3831]\n",
      " [   14 12421]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "\n",
    "make_predictions(model, X, y)\n",
    "\n",
    "make_predictions(model, TX, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.312294629958\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 优化算法参数\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "          fit_params={}, iid=True, n_iter=100, n_jobs=1,\n",
      "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DFC7A76518>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          scoring=None, verbose=0)\n",
      "0.312294629657\n",
      "0.989903640912\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X, y)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}